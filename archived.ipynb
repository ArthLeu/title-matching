{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import search_sentences\n",
    "from custom_classes import PosMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tqdm.pandas()\n",
    "\n",
    "i = 0\n",
    "limit = 100\n",
    "p = 5\n",
    "q = 4\n",
    "pre_tf = PosMap(p)\n",
    "post_tf = PosMap(q)\n",
    "\n",
    "for row in tqdm(train_df.iterrows()):\n",
    "    label = row[1][\"cleaned_label\"]\n",
    "    text = row[1][\"text\"].lower()\n",
    "    act, deact = search_sentences(label, text, pre=p, post=q)\n",
    "\n",
    "    for j in range(len(act)):\n",
    "        pre_words = act[j].split()[::-1]\n",
    "        post_words = deact[j].split()\n",
    "        for k in range(min([len(pre_words), p])):\n",
    "            try:\n",
    "                word = pre_words[k]\n",
    "                pre_tf[k][word] += 1\n",
    "            except IndexError:\n",
    "                print(act[j])\n",
    "        \n",
    "        for k in range(min([len(post_words), q])):\n",
    "            try:\n",
    "                word = post_words[k]\n",
    "                post_tf[k][word] += 1\n",
    "            except IndexError:\n",
    "                print(deact[j])\n",
    "\n",
    "    i += 1\n",
    "    #if i >= limit: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tf.plot(idx=0) # the first closest pre words\n",
    "pre_tf.plot(idx=1) # the second closest pre words\n",
    "pre_tf.plot(idx=2) # the third\n",
    "pre_tf.plot(idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_tf.plot(idx=0)\n",
    "post_tf.plot(idx=1)\n",
    "post_tf.plot(idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1: FUZZY MATCH\n",
    "value = fuzz.partial_ratio(sentence.lower(), known_label) # I moved .lower() here\n",
    "if value > 85 and value < 100:\n",
    "     print('value: ', str(value), known_label) # Alex, you might wanna see what this prints\n",
    "     cleaned_labels.append(clean_text(known_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 2: for unknown labels\n",
    "    # sentence filtering (Longest Consecutive Capitalization)\n",
    "    #print(sentence)\n",
    "    length, rate, filtered_sentence = LCC(sentence)\n",
    "    if rate <= 0 or length == 0 or (length == 1 and not sentence.isupper()): \n",
    "        continue # no consecutive caps found\n",
    "    # <insert classifier here>\n",
    "    else:\n",
    "        for keyword in [\"dataset\", \"data\", \"database\", \"survey\", \"study\", \"research\", \"statistics\"]:\n",
    "            if keyword in filtered_sentence.lower():\n",
    "                #pass\n",
    "                cleaned_labels.append(clean_text(filtered_sentence)) # naive"
   ]
  }
 ]
}