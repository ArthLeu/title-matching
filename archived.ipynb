{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Code Snippets that are Archived\n",
    "Does not work when run directly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fuzzywuzzy import fuzz\n",
    "#from tqdm.autonotebook import tqdm\n",
    "#from __future__ import unicode_literals, print_function\n",
    "#import plac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import search_sentences\n",
    "from custom_classes import PosMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tqdm.pandas()\n",
    "\n",
    "i = 0\n",
    "limit = 100\n",
    "p = 5\n",
    "q = 4\n",
    "pre_tf = PosMap(p)\n",
    "post_tf = PosMap(q)\n",
    "\n",
    "for row in tqdm(train_df.iterrows()):\n",
    "    label = row[1][\"cleaned_label\"]\n",
    "    text = row[1][\"text\"].lower()\n",
    "    act, deact = search_sentences(label, text, pre=p, post=q)\n",
    "\n",
    "    for j in range(len(act)):\n",
    "        pre_words = act[j].split()[::-1]\n",
    "        post_words = deact[j].split()\n",
    "        for k in range(min([len(pre_words), p])):\n",
    "            try:\n",
    "                word = pre_words[k]\n",
    "                pre_tf[k][word] += 1\n",
    "            except IndexError:\n",
    "                print(act[j])\n",
    "        \n",
    "        for k in range(min([len(post_words), q])):\n",
    "            try:\n",
    "                word = post_words[k]\n",
    "                post_tf[k][word] += 1\n",
    "            except IndexError:\n",
    "                print(deact[j])\n",
    "\n",
    "    i += 1\n",
    "    #if i >= limit: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tf.plot(idx=0) # the first closest pre words\n",
    "pre_tf.plot(idx=1) # the second closest pre words\n",
    "pre_tf.plot(idx=2) # the third\n",
    "pre_tf.plot(idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_tf.plot(idx=0)\n",
    "post_tf.plot(idx=1)\n",
    "post_tf.plot(idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1: FUZZY MATCH\n",
    "value = fuzz.partial_ratio(sentence.lower(), known_label) # I moved .lower() here\n",
    "if value > 85 and value < 100:\n",
    "     print('value: ', str(value), known_label) # Alex, you might wanna see what this prints\n",
    "     cleaned_labels.append(clean_text(known_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 2: for unknown labels\n",
    "    # sentence filtering (Longest Consecutive Capitalization)\n",
    "    #print(sentence)\n",
    "    length, rate, filtered_sentence = LCC(sentence)\n",
    "    if rate <= 0 or length == 0 or (length == 1 and not sentence.isupper()): \n",
    "        continue # no consecutive caps found\n",
    "    # <insert classifier here>\n",
    "    else:\n",
    "        for keyword in [\"dataset\", \"data\", \"database\", \"survey\", \"study\", \"research\", \"statistics\"]:\n",
    "            if keyword in filtered_sentence.lower():\n",
    "                #pass\n",
    "                cleaned_labels.append(clean_text(filtered_sentence)) # naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy version 3.0+ requires Example wrapper for texts and annotations\n",
    "for batch in tqdm(batches):\n",
    "    for texts, annotations in tqdm(TRAIN_DATA):\n",
    "        for texts, annotations in batch:\n",
    "            doc = nlp.make_doc(texts) # version >= 3\n",
    "            example = Example.from_dict(doc, annotations) # version >= 3\n",
    "            nlp.update(\n",
    "                [example],\n",
    "                drop=0.5, \n",
    "                sgd=optimizer,\n",
    "                losses=losses) # version >= 3"
   ]
  }
 ]
}